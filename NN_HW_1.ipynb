{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN-HW-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPNQPNm9L1UJFe7tSnsXFLu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhivyapm/CS7357/blob/master/NN_HW_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klss2iUT-0QY"
      },
      "source": [
        "#import the neccessary libraries\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRPCNcoq-2nx"
      },
      "source": [
        "#read the test_set from website location to csv format\r\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/kevinsuo/CS7357/01184c2ee36c16f1f517022d24d6b1583c008d8d/project/1/data/test_set.csv\")\r\n",
        "\r\n",
        "#read the train_set from website location to csv format\r\n",
        "train = pd.read_csv(\"https://raw.githubusercontent.com/kevinsuo/CS7357/01184c2ee36c16f1f517022d24d6b1583c008d8d/project/1/data/train_set.csv\")\r\n",
        "\r\n",
        "#read the validation_set from website location to csv format\r\n",
        "validation = pd.read_csv(\"https://raw.githubusercontent.com/kevinsuo/CS7357/01184c2ee36c16f1f517022d24d6b1583c008d8d/project/1/data/validation_set.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUjvteTn-54N"
      },
      "source": [
        "#function to remove the duplicate words in each row in a dataset\r\n",
        "def unique_words(l):\r\n",
        "    #creating list to store the unique words\r\n",
        "    uwords = []\r\n",
        "    # for loop to run each row in a dataset and append the result in uwords\r\n",
        "    [uwords.append(x) for x in l if x not in uwords]\r\n",
        "    return uwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0csFKG3l-90A"
      },
      "source": [
        "def words(train):\r\n",
        "    u_words_train = []\r\n",
        "\r\n",
        "    #for loop to run for entire dataset\r\n",
        "    for i in range(0,len(train)):\r\n",
        "        #append the split words from unique_words function \r\n",
        "        u_words_train.append(unique_words(train['Words (split by space)'][i].split()))\r\n",
        "    return u_words_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZkRmUbYMrlF"
      },
      "source": [
        "#storing the unique words from u_words_train list to train dataframe as column called \"unique_words\"\r\n",
        "train['unique_words'] = words(train)\r\n",
        "#storing the unique words from u_words_test list to test dataframe as column called \"unique_words\"\r\n",
        "test['unique_words'] = words(test)\r\n",
        "#storing the unique words from u_words_valid list to validation dataframe as column called \"unique_words\"\r\n",
        "validation['unique_words'] = words(validation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr8uyoybQpxH"
      },
      "source": [
        "train_y = pd.get_dummies(train['label'])\r\n",
        "train_y = np.array(train_y)\r\n",
        "validation_y = pd.get_dummies(validation['label'])\r\n",
        "validation_y = np.array(validation_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7VGMYWINMVV"
      },
      "source": [
        "train['clean_sent'] = train['unique_words'].apply(lambda x: '  '.join(x))\r\n",
        "test['clean_sent'] = test['unique_words'].apply(lambda x: '  '.join(x))\r\n",
        "validation['clean_sent'] = validation['unique_words'].apply(lambda x: '  '.join(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr6zYIvD-Xvb"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer\r\n",
        "\r\n",
        "mlb = MultiLabelBinarizer()\r\n",
        "train_X = pd.DataFrame(mlb.fit_transform([x for x in train['unique_words']]),columns=mlb.classes_)\r\n",
        "train_X = np.array(train_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGhpxex-_Bzg",
        "outputId": "dc554874-1c07-4c6a-b7ac-6f1b23c1f004"
      },
      "source": [
        "\r\n",
        "test_X = pd.DataFrame(mlb.transform([x for x in test['unique_words']]),columns=mlb.classes_)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['abused', 'abuses', 'accused', 'acknowledges', 'adamant', 'add', 'addiction', 'adds', 'agencies', 'agency', 'aggressively', 'agreement', 'ahead', 'airlines', 'album', 'alert', 'allegedly', 'alliance', 'also', 'although', 'alzheimer', 'america', 'aminos', 'amputee', 'andromeda', 'anglicans', 'anhalt', 'announce', 'another', 'antarctica', 'antidote', 'anymore', 'apart', 'apologies', 'appeal', 'armed', 'arrest', 'arrives', 'arrogance', 'arthurs', 'assault', 'ate', 'attorneys', 'au', 'audio', 'authorized', 'autos', 'await', 'awry', 'babe', 'bachelors', 'baggage', 'bangalore', 'bangladesh', 'bans', 'barcelona', 'based', 'battalion', 'bay', 'beaten', 'beauticians', 'bed', 'beer', 'behind', 'between', 'bloc', 'blowing', 'boast', 'bollywood', 'bombs', 'bonuses', 'books', 'borders', 'born', 'boston', 'braff', 'branch', 'brangelina', 'brit', 'brith', 'briton', 'brokers', 'bulgaria', 'burberry', 'buried', 'bury', 'busy', 'buyer', 'cameras', 'cameron', 'canada', 'canadian', 'canadians', 'canal', 'cancels', 'canete', 'canned', 'carbon', 'carl', 'carlos', 'carolina', 'cars', 'catania', 'cause', 'caused', 'celebrations', 'censure', 'cervical', 'chad', 'chance', 'charged', 'chargers', 'charges', 'charts', 'chic', 'chinese', 'chrysler', 'church', 'churches', 'chvez', 'cia', 'circuit', 'cites', 'citing', 'civics', 'clean', 'climbing', 'closes', 'clue', 'cnn', 'co', 'coast', 'coating', 'cocoa', 'collaborator', 'college', 'columbia', 'comatose', 'comfort', 'comrade', 'congressman', 'conjuring', 'conspiracy', 'controls', 'cooperation', 'copyright', 'corn', 'cosmos', 'counter', 'couple', 'coupon', 'court', 'cousin', 'creating', 'crossroads', 'cultural', 'cup', 'curfew', 'curl', 'daddy', 'dallas', 'damaged', 'dangers', 'dayers', 'deceased', 'defendants', 'defends', 'dental', 'depression', 'depths', 'despite', 'detain', 'detects', 'diaz', 'didn', 'difficult', 'digs', 'dining', 'diplomat', 'disarmament', 'discover', 'disease', 'diseases', 'divide', 'doherty', 'downloads', 'dress', 'drive', 'dropped', 'dubai', 'due', 'e', 'easy', 'eat', 'egypt', 'eid', 'ejected', 'emi', 'ends', 'engaged', 'engine', 'enrichment', 'entertainment', 'era', 'error', 'erupt', 'escalates', 'ethiopia', 'euphoric', 'european', 'executed', 'execution', 'exists', 'exit', 'exotic', 'expect', 'experiment', 'expulsion', 'extinguisher', 'extremist', 'eye', 'fading', 'fame', 'fans', 'faster', 'fatah', 'faults', 'ferry', 'festival', 'fetal', 'finishes', 'fires', 'firms', 'five', 'florida', 'footage', 'football', 'forecasters', 'former', 'founders', 'fourth', 'frat', 'frederic', 'full', 'fully', 'g', 'gains', 'galactic', 'ganguly', 'gap', 'gene', 'genghis', 'gently', 'georgia', 'ghost', 'giants', 'giles', 'girlfriend', 'gives', 'glaciers', 'god', 'goes', 'golden', 'gop', 'got', 'grammys', 'grimaces', 'guantanamo', 'guilty', 'gym', 'half', 'hamas', 'hanging', 'harry', 'harvard', 'havana', 'haven', 'havoc', 'hazing', 'heard', 'heartbroken', 'heated', 'helios', 'him', 'homemade', 'hometown', 'housewives', 'housing', 'houston', 'hubble', 'hugging', 'humans', 'hungarian', 'hungary', 'hunt', 'hyped', 'icbms', 'iceland', 'il', 'immigrants', 'inaugural', 'include', 'increase', 'indian', 'indicted', 'infamous', 'info', 'injured', 'injury', 'inquest', 'inspires', 'install', 'insurgents', 'intensity', 'inventor', 'investigators', 'involved', 'iranians', 'irks', 'italian', 'ivory', 'ivrea', 'jobs', 'joburg', 'johnny', 'joined', 'jon', 'jonbenet', 'jong', 'joseph', 'journalists', 'jump', 'jury', 'justin', 'kampala', 'kate', 'khan', 'kick', 'kidnap', 'killer', 'kit', 'klm', 'krueger', 'l', 'lack', 'lags', 'lasting', 'latest', 'launches', 'laws', 'lays', 'leak', 'lean', 'left', 'lesson', 'lethargic', 'libby', 'lily', 'link', 'links', 'list', 'listeria', 'live', 'longer', 'loss', 'lost', 'louis', 'lowcountry', 'luxury', 'lyrics', 'magnet', 'mainstay', 'makeovers', 'making', 'malawi', 'management', 'mancuso', 'manila', 'marijuana', 'marred', 'marrying', 'mates', 'matthews', 'maybe', 'mbeki', 'measure', 'medicinal', 'melting', 'members', 'memorial', 'merge', 'message', 'messi', 'midwest', 'might', 'mild', 'mile', 'millennium', 'mission', 'mixed', 'mocks', 'money', 'mongolia', 'month', 'mortar', 'mountain', 'mourn', 'mozambique', 'mr', 'ms', 'mughrabi', 'murdoch', 'muscle', 'muslims', 'my', 'myspace', 'napster', 'nazi', 'nbc', 'neal', 'nearly', 'needed', 'neighbors', 'nice', 'nielsen', 'northeaster', 'nude', 'offensive', 'oldest', 'opponent', 'oprah', 'optimism', 'orbit', 'outcry', 'overrun', 'own', 'owners', 'oxfam', 'packs', 'palestinians', 'pandas', 'pap', 'papon', 'parachutist', 'paris', 'parks', 'parliament', 'passes', 'patrol', 'pats', 'paychecks', 'payout', 'pays', 'pelting', 'performance', 'peron', 'person', 'petersburg', 'pick', 'picky', 'pictures', 'planet', 'planning', 'playboy', 'plug', 'plunge', 'poised', 'poisoning', 'polar', 'policy', 'popping', 'portege', 'poses', 'positions', 'possible', 'presidential', 'prestige', 'prevention', 'prime', 'prison', 'profits', 'program', 'promises', 'prosecutors', 'protects', 'protestors', 'protests', 'prove', 'pull', 'punished', 'punter', 'quarter', 'quest', 'quitting', 'r', 'ragged', 'rape', 'reach', 'reaction', 'readies', 'realize', 'rebel', 'rebuke', 'rebukes', 'recalled', 'receiving', 'recovery', 'regain', 'regrets', 'rejected', 'related', 'religion', 'remarks', 'remote', 'repellent', 'rescues', 'research', 'researcher', 'resigns', 'resort', 'restrict', 'rests', 'retake', 'reveal', 'revolutionary', 'ride', 'robredo', 'rockers', 'romania', 'root', 'round', 'roundup', 'routine', 'rowdy', 'rulings', 'runway', 'rupert', 'rwandan', 'same', 'sarwan', 'scheme', 'schoolhouse', 'schools', 'scion', 'scouts', 'seals', 'secrets', 'seek', 'seen', 'self', 'senator', 'senators', 'serena', 'setback', 'shame', 'she', 'sheet', 'shells', 'shelters', 'shia', 'shirt', 'shoplifters', 'shoppers', 'shopping', 'shores', 'short', 'shortening', 'showers', 'shuts', 'sick', 'siege', 'siesta', 'sight', 'sign', 'since', 'singled', 'skates', 'ski', 'skip', 'slammed', 'slams', 'slap', 'slashes', 'slide', 'slips', 'smacks', 'smokestacks', 'smoking', 'snowbirds', 'softly', 'sold', 'sorry', 'spacecraft', 'spain', 'sparks', 'speaks', 'spring', 'spy', 'squad', 'squadron', 'stabbing', 'staging', 'standoff', 'starting', 'stave', 'stays', 'stealing', 'stenson', 'stepping', 'stewart', 'stonehenge', 'story', 'stoves', 'strengthen', 'strips', 'studios', 'subs', 'success', 'suffer', 'summary', 'svindal', 'switch', 'syria', 'tailors', 'taiwan', 'taking', 'telecoms', 'temporary', 'tennessee', 'tensions', 'terrorism', 'texan', 'thinks', 'timberlake', 'times', 'tivo', 'toasty', 'torn', 'toshiba', 'touch', 'tourists', 'tournament', 'tout', 'tow', 'track', 'tracked', 'trailblazing', 'train', 'tres', 'trilateral', 'trim', 'troop', 'troubles', 'truck', 'trusted', 'tuition', 'tuna', 'turkey', 'turner', 'turnpike', 'turns', 'ukraine', 'un', 'unarmed', 'unions', 'unrest', 'unsafe', 'uprising', 'upswing', 'useful', 'users', 'vaccination', 'vii', 'village', 'violators', 'visions', 'von', 'vote', 'wambaugh', 'watch', 'watchdog', 'ways', 'wc', 'weekly', 'weeps', 'wellcome', 'went', 'whistle', 'whole', 'whoopi', 'wider', 'wildfire', 'wines', 'wives', 'wooing', 'wreaks', 'yahoo', 'yen', 'yourself', 'yuan', 'zach', 'zoo'] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg3F6dfA_RYU",
        "outputId": "77871dae-41af-4520-9291-cc28a50aaa4d"
      },
      "source": [
        "validation_X = pd.DataFrame(mlb.transform([x for x in validation['unique_words']]),columns=mlb.classes_)\r\n",
        "validation_X = np.array(validation_X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_label.py:987: UserWarning: unknown class(es) ['abortion', 'accept', 'accidental', 'act', 'active', 'addicted', 'addiction', 'aftermath', 'agents', 'ahead', 'alert', 'alzheimer', 'amateur', 'analysis', 'anatomy', 'angels', 'another', 'appealing', 'arena', 'arm', 'arms', 'arrests', 'arrogant', 'ashore', 'asif', 'assess', 'attackers', 'attends', 'austrian', 'author', 'avoid', 'awarded', 'awareness', 'babysitter', 'backfire', 'ballerina', 'bananaconda', 'bank', 'basics', 'beating', 'become', 'bed', 'behind', 'bernanke', 'bernard', 'bernhard', 'betty', 'between', 'beyond', 'bike', 'binge', 'blazing', 'blissing', 'bloody', 'boast', 'bodies', 'bombers', 'bomblets', 'books', 'boom', 'bopara', 'born', 'bosses', 'bought', 'break', 'breakup', 'britons', 'bruce', 'budapest', 'built', 'bulls', 'burberry', 'buried', 'bust', 'button', 'campaigns', 'canadian', 'canceled', 'cancellations', 'cancels', 'candidate', 'career', 'cargo', 'carlo', 'carphone', 'carrefour', 'carter', 'cases', 'category', 'century', 'certain', 'cesareans', 'chaps', 'charles', 'charlie', 'cheat', 'chicago', 'chinese', 'chopper', 'cia', 'cited', 'clashes', 'classes', 'clean', 'cleared', 'cleveland', 'climb', 'closings', 'cocoa', 'cold', 'coli', 'coma', 'commander', 'commentary', 'common', 'concedes', 'concert', 'cook', 'copters', 'county', 'court', 'covers', 'cowell', 'crackdown', 'crackup', 'crime', 'crippled', 'cripples', 'criticises', 'cross', 'crosswalks', 'cup', 'curfew', 'cyberspace', 'dakar', 'dam', 'damage', 'dance', 'davydenko', 'declared', 'decries', 'delays', 'demands', 'denounced', 'departed', 'depiction', 'deported', 'deputy', 'despite', 'detained', 'development', 'diplomat', 'disaster', 'discovered', 'disease', 'disinfection', 'doctor', 'doctors', 'doing', 'donation', 'door', 'downhill', 'drama', 'drawing', 'drink', 'drive', 'drought', 'duel', 'dull', 'durant', 'e', 'earth', 'efforts', 'eiffel', 'elephant', 'embassy', 'endangered', 'ending', 'ends', 'enemies', 'engineer', 'engineers', 'environmentalism', 'equal', 'escalation', 'estate', 'european', 'evacuees', 'excerpt', 'exec', 'facing', 'fails', 'falls', 'family', 'famous', 'fans', 'fascist', 'fatah', 'fault', 'fence', 'ferrari', 'ferrer', 'feud', 'fighters', 'fighting', 'firefox', 'fit', 'fitness', 'flirt', 'flirts', 'florida', 'flow', 'fm', 'follows', 'football', 'ford', 'founders', 'four', 'fox', 'frankfurt', 'frantic', 'freedoms', 'fresh', 'friend', 'frustration', 'full', 'fun', 'furnace', 'g', 'gators', 'general', 'gibson', 'girlhood', 'glad', 'glamour', 'goes', 'goetschl', 'going', 'golden', 'gonzalez', 'gps', 'grammys', 'gras', 'gravity', 'gray', 'great', 'greek', 'griffiths', 'grip', 'grisham', 'gritty', 'growth', 'gun', 'gyllenhaal', 'halted', 'hamas', 'hammers', 'hang', 'harrassment', 'harris', 'harvard', 'haul', 'hawks', 'healthier', 'hi', 'highest', 'highlights', 'highs', 'higley', 'hinders', 'historic', 'hiv', 'honour', 'hopeless', 'hour', 'housewives', 'hp', 'hunt', 'hurting', 'idea', 'immoral', 'importance', 'important', 'inconvenient', 'independence', 'infection', 'infertile', 'inflation', 'injury', 'inquest', 'inventor', 'investigate', 'ipo', 'items', 'jackass', 'jakarta', 'janeiro', 'job', 'john', 'johnny', 'jose', 'juliet', 'jump', 'kashmir', 'keeps', 'kerry', 'kick', 'kidnappers', 'knowing', 'koreans', 'koreas', 'kosovo', 'kurdish', 'laid', 'landmark', 'largely', 'las', 'launch', 'launches', 'lawmaker', 'lawmakers', 'laws', 'lay', 'lee', 'letting', 'liar', 'lieut', 'light', 'lightly', 'lines', 'links', 'list', 'listing', 'll', 'locate', 'lohan', 'look', 'looking', 'loom', 'loss', 'lost', 'loye', 'lust', 'luxury', 'lyrics', 'mac', 'machinery', 'maggie', 'mailing', 'maker', 'making', 'mallorca', 'mammal', 'manila', 'map', 'marcia', 'mardi', 'marijuana', 'marine', 'marital', 'marries', 'marsupials', 'masako', 'matthews', 'maybe', 'mbeki', 'media', 'mega', 'memo', 'memories', 'merge', 'mexican', 'might', 'miniature', 'misguided', 'missed', 'mix', 'mixed', 'mobile', 'mockingbird', 'modeling', 'money', 'most', 'motion', 'mourn', 'muhammad', 'munsters', 'myspace', 'mytravel', 'nap', 'national', 'natural', 'nature', 'navy', 'neal', 'nerve', 'networking', 'newsom', 'nicaragua', 'nielsen', 'night', 'nightmare', 'nipple', 'objects', 'odysseus', 'offering', 'offing', 'ojai', 'okays', 'opera', 'opt', 'options', 'osorio', 'outdated', 'overdose', 'oversight', 'own', 'owners', 'pacers', 'package', 'pact', 'paid', 'pain', 'palestinians', 'pantful', 'paris', 'parliament', 'pastor', 'pathetic', 'patients', 'pays', 'phones', 'phosphorous', 'physicists', 'piece', 'pit', 'plague', 'planning', 'plunges', 'poet', 'poetry', 'poisoning', 'politicians', 'politics', 'pony', 'poor', 'portugal', 'potency', 'potential', 'poverty', 'preserve', 'press', 'protesters', 'protests', 'race', 'radical', 'rape', 'reach', 'reaches', 'rebound', 'reclusive', 'regret', 'regrets', 'rehab', 'reid', 'relatives', 'relives', 'remedy', 'replace', 'reported', 'reprieve', 'researchers', 'resigns', 'resists', 'resort', 'respect', 'rethink', 'reveal', 'revealing', 'revells', 'revs', 'ride', 'rides', 'rig', 'rings', 'riots', 'rise', 'road', 'roamed', 'rock', 'rocket', 'romeo', 'rsa', 'rupp', 'sabotage', 'sadr', 'san', 'sanctions', 'sand', 'scattered', 'scenario', 'schools', 'schuey', 'score', 'scorns', 'scorpion', 'scrubs', 'secrets', 'seeds', 'seeing', 'seek', 'seen', 'sees', 'senator', 'send', 'serbia', 'serendipity', 'sevilla', 'shares', 'sharks', 'sheen', 'shells', 'shelves', 'shiite', 'shock', 'shoppers', 'short', 'shots', 'showing', 'shuts', 'siestas', 'signals', 'signed', 'silly', 'simple', 'singer', 'sitcom', 'six', 'sleeping', 'sleuths', 'slimmer', 'slows', 'smokers', 'snapped', 'sneakers', 'snowed', 'soar', 'soars', 'sober', 'social', 'soil', 'solution', 'source', 'sparks', 'special', 'spy', 'standoff', 'stands', 'stanford', 'station', 'stationary', 'status', 'stifle', 'strategy', 'stupid', 'substantial', 'suburb', 'success', 'successful', 'successfully', 'suit', 'surging', 'survives', 'swallow', 'swallowed', 'swingers', 'symbolic', 'talking', 'targeted', 'tendencies', 'tent', 'terai', 'terrorism', 'tests', 'thanks', 'thomas', 'thrillville', 'tiger', 'tot', 'tourist', 'towed', 'tower', 'toxic', 'tracking', 'train', 'trains', 'treading', 'trend', 'trolleys', 'troubling', 'trucks', 'true', 'trump', 'trumps', 'truths', 'trying', 'tube', 'turkish', 'uganda', 'un', 'unity', 'unlikely', 'unruly', 'upset', 'upward', 'v', 'variety', 'vegas', 'victim', 'victorious', 'vietnamese', 'vikes', 'visitors', 'volkswagen', 'vote', 'vs', 'walters', 'warehouse', 'warioware', 'watada', 'weather', 'weekly', 'were', 'west', 'when', 'wicket', 'winter', 'withnail', 'wizardry', 'wolves', 'writers', 'ya', 'yet', 'yvonne', 'zabul', 'zealand', 'zimbabwe'] will be ignored\n",
            "  .format(sorted(unknown, key=str)))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYKIs5XjRUP7"
      },
      "source": [
        "class distanceMetrics:\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "\r\n",
        "        pass\r\n",
        "        \r\n",
        "    def euclideanDistance(self, vector1, vector2):\r\n",
        "\r\n",
        "        self.vectorA, self.vectorB = vector1, vector2\r\n",
        "        if len(self.vectorA) != len(self.vectorB):\r\n",
        "            raise ValueError(\"Undefined for sequences of unequal length.\")\r\n",
        "        distance = 0.0\r\n",
        "        for i in range(len(self.vectorA)-1):\r\n",
        "            distance += (self.vectorA[i] - self.vectorB[i])**2\r\n",
        "        return (distance)**0.5\r\n",
        "    \r\n",
        "    def manhattanDistance(self, vector1, vector2):\r\n",
        "\r\n",
        "        self.vectorA, self.vectorB = vector1, vector2\r\n",
        "        if len(self.vectorA) != len(self.vectorB):\r\n",
        "            raise ValueError(\"Undefined for sequences of unequal length.\")\r\n",
        "        return np.abs(np.array(self.vectorA) - np.array(self.vectorB)).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on7h5cV1W4Aw"
      },
      "source": [
        "class kNNClassifier:\r\n",
        "\r\n",
        "    def __init__(self,k = 3, distanceMetric = 'euclidean'):\r\n",
        "        pass\r\n",
        "    \r\n",
        "    def fit(self, xTrain, yTrain):\r\n",
        "        assert len(xTrain) == len(yTrain)\r\n",
        "        self.trainData = xTrain\r\n",
        "        self.trainLabels = yTrain\r\n",
        "\r\n",
        "    def getNeighbors(self, testRow):\r\n",
        "        calcDM = distanceMetrics()\r\n",
        "        distances = []\r\n",
        "        for i, trainRow in enumerate(self.trainData):\r\n",
        "            if self.distanceMetric == 'euclidean':\r\n",
        "                distances.append([trainRow, calcDM.euclideanDistance(testRow, trainRow), self.trainLabels[i]])\r\n",
        "            elif self.distanceMetric == 'manhattan':\r\n",
        "                distances.append([trainRow, calcDM.manhattanDistance(testRow, trainRow), self.trainLabels[i]])\r\n",
        "            elif self.distanceMetric == 'hamming':\r\n",
        "                distances.append([trainRow, calcDM.hammingDistance(testRow, trainRow), self.trainLabels[i]])\r\n",
        "            distances.sort(key=operator.itemgetter(1))\r\n",
        "\r\n",
        "        neighbors = []\r\n",
        "        for index in range(self.k):\r\n",
        "            neighbors.append(distances[index])\r\n",
        "        return neighbors\r\n",
        "    def predict(self, xTest, k, distanceMetric):\r\n",
        "        '''\r\n",
        "        Description:\r\n",
        "            Apply kNN model on test data\r\n",
        "        Input:\r\n",
        "            xTest: testing data with coordinates\r\n",
        "            k: number of neighbors\r\n",
        "            distanceMetric: technique to calculate distance metric\r\n",
        "        Output:\r\n",
        "            predicted label \r\n",
        "        '''\r\n",
        "        self.testData = xTest\r\n",
        "        self.k = k\r\n",
        "        self.distanceMetric = distanceMetric\r\n",
        "        predictions = []\r\n",
        "        \r\n",
        "        for i, testCase in enumerate(self.testData):\r\n",
        "            neighbors = self.getNeighbors(testCase)\r\n",
        "            #print(neighbors)\r\n",
        "            output= [row[-1] for row in neighbors]\r\n",
        "            #print(output)\r\n",
        "            prediction = np.max(set(output, key=output.count))\r\n",
        "            predictions.append(prediction)\r\n",
        "        \r\n",
        "        return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpdDpXSLvDQz"
      },
      "source": [
        "def printMetrics(actual, predictions):\r\n",
        "    '''\r\n",
        "    Description:\r\n",
        "        This method calculates the accuracy of predictions\r\n",
        "    '''\r\n",
        "    #assert len(actual) == len(predictions)\r\n",
        "    correct = 0\r\n",
        "    for i in range(len(actual)):\r\n",
        "        if (actual[i] == predictions[i]).all():\r\n",
        "            correct += 1\r\n",
        "    print(\"Acuracy of kNN model: \",correct / float(len(actual)) * 100.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfNvTTGJvE6H"
      },
      "source": [
        "\r\n",
        "knn = kNNClassifier()\r\n",
        "knn.fit(train_X, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "0_5ZxDspvNxz",
        "outputId": "8d1d613b-3ada-4080-fc6f-52724ef32f67"
      },
      "source": [
        "import operator\r\n",
        "eucPredictions = knn.predict(validation_X, 3, 'manhattan')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-401-d340863f3f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meucPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'manhattan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-398-678268e74cfa>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, xTest, k, distanceMetric)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mneighbors\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I18wllpd3DM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}